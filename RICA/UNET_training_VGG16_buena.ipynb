{"cells":[{"cell_type":"markdown","metadata":{"id":"atMz3V5D39bm"},"source":["[consejos google pro](https://colab.research.google.com/notebooks/pro.ipynb)"]},{"cell_type":"markdown","metadata":{"id":"fG6Cgs5tcR6v"},"source":["# SEGMENTACION MEDIANTE U-NET + VGG16 y\n","\n","\n","    def dice_loss(y_true, y_pred, smooth=1) #smooth=1e-5\n","      y_true = tf.cast(y_true, tf.float32)\n","      intersection = tf.reduce_sum(y_true * y_pred)\n","      suma = tf.reduce_sum(y_true) + tf.reduce_sum(y_pred)\n","      dice_score = (2.0 * intersection + smooth) / (suma + smooth)\n","      dice_loss = 1.0 - dice_score\n","      return dice_loss"]},{"cell_type":"markdown","metadata":{"id":"vWMjOf8FdmiJ"},"source":["## 1.4 Codigo"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"NQHajQVbD7rs"},"outputs":[],"source":["# EL DATA AUGMENTATION QUE VA ES EL DE ESTA NOTEBOOK\n","\n","\n","## Imports\n","import os\n","import random\n","\n","import numpy as np\n","import cv2\n","import matplotlib.pyplot as plt\n","\n","import tensorflow as tf\n","from tensorflow import keras\n","\n","\n","## Seeding\n","seed = 2019\n","random.seed = seed\n","np.random.seed = seed\n","tf.seed = seed"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"VKr7BkqhuW0l"},"outputs":[],"source":["from PIL import Image\n","\n","def image_display(image_pathlist, mask_pathlist, index):\n","    # input: image and mask filepath and the index\n","    # output matplotlib images\n","    image = Image.open(image_pathlist[index]).convert(\"L\") #agregamos .convert(\"L\")\n","    imagearray = np.array(image)\n","    print('Image shape: ', imagearray.shape)\n","\n","\n","    mask = Image.open(mask_pathlist[index]).convert(\"L\") #agregamos .convert(\"L\")\n","    maskarray = np.array(mask)\n","    print('Mask shape: ', maskarray.shape)\n","\n","    #fig, ax = plt.subplots(3,figsize=(5,10))\n","    fig, ax = plt.subplots(1,3,figsize=(14,4)) #cambié para que se vean horizontales\n","    ax[0].imshow(imagearray, aspect='auto', cmap='gray')\n","    ax[1].imshow(maskarray, aspect='auto', cmap='gray')\n","    ax[2].imshow(imagearray, aspect='auto', cmap = 'gray')\n","    ax[2].imshow(maskarray, cmap = 'Reds', aspect='auto', alpha = 0.4)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ZSc-OT_qZnMY"},"outputs":[],"source":["def finetune_unfreezeall(base_model):\n","    base_model = base_model\n","\n","    # unfreeze the contracting path and freeze the expanding path\n","    for layer in base_model.layers:\n","        if layer.name in ['block1_conv1', 'block1_conv2', 'block1_pool',\n","                          'block2_conv1', 'block2_conv2', 'block2_pool',\n","                          'block3_conv1', 'block3_conv2', 'block3_conv3', 'block3_pool',\n","                          'block4_conv1', 'block4_conv2', 'block4_conv3', 'block4_pool',\n","                          'block5_conv1', 'block5_conv2', 'block5_conv3']:\n","            layer.trainable = True\n","\n","    return base_model"]},{"cell_type":"markdown","metadata":{"id":"bLBCPCmtJ5nY"},"source":["## Clase para Aumentacion de datos completa, con esquinas y doble flip"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"3rHAorZ4SXpJ"},"outputs":[],"source":["class DataAugmentation:\n","    def __init__(self, images):\n","        self.images = images\n","        self.output = []\n","\n","    def process_images(self):\n","        image_files = self.images\n","        for file_name in image_files:\n","            image = file_name\n","            if image.shape[0] < 512:\n","                diff_rows = 512 - image.shape[0]\n","                image = np.vstack((image, np.zeros((diff_rows, image.shape[1]), dtype=np.uint8)))\n","\n","            if image.shape[1] < 512:\n","                diff_cols = 512 - image.shape[1]\n","                image = np.hstack((image, np.zeros((image.shape[0], diff_cols), dtype=np.uint8)))\n","\n","            self.apply_transformations(image)\n","\n","\n","    def apply_transformations(self, image):\n","\n","\n","\n","        for i in [0]: # range(-2,3,4):#range(-4,5,4):   #range(-4,5,2)=[-4,-2, 0, 2, 4]\n","          for j in range(-2,3,4):  #range(-4,5,4)=[-4, 0, 4]\n","            translate = self.apply_translation(image, 32 * i, 32 * j)\n","            translated_cropped = self.adjust_image_size(translate, 512, 512)\n","            self.save_transformed_images(translated_cropped)\n","\n","            flip_horizontal_right = cv2.flip(translated_cropped, 1)\n","            self.save_transformed_images(flip_horizontal_right)\n","\n","            flip_vertical_right = cv2.flip(translated_cropped, 0)\n","            self.save_transformed_images(flip_vertical_right)\n","\n","            flip_both_right = cv2.flip(flip_horizontal_right, 0)  #agregado!\n","            self.save_transformed_images(flip_both_right)     #agregado!\n","\n","\n","\n","    def apply_translation(self, image, x_offset, y_offset):\n","        rows, cols = image.shape\n","        M = np.float32([[1, 0, x_offset], [0, 1, y_offset]])\n","        translated_image = cv2.warpAffine(image, M, (cols, rows))\n","        return translated_image\n","\n","    def save_transformed_images(self, image):\n","\n","        self.output.append(image)\n","\n","    def save_image(self, image):\n","        self.output.append(image)\n","\n","\n","    def adjust_image_size(self, image, target_width, target_height):\n","        height, width = image.shape\n","        x_offset = (width - target_width) // 2\n","        y_offset = (height - target_height) // 2\n","        new_image = image[y_offset:y_offset + target_height, x_offset:x_offset + target_width]\n","\n","        return new_image\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"5Ssiw-Cv1bP0"},"outputs":[],"source":["def image_comparac(monocroma, etiqueta, red):\n","    # input: image and mask filepath and the index\n","    # output matplotlib images\n","\n","    fig, ax = plt.subplots(1,4,figsize=(16,4)) #cambié para que se vean horizontales\n","    ax[0].imshow(monocroma, aspect='auto', cmap='gray')\n","    ax[0].set_title('monocroma')\n","    ax[1].imshow(etiqueta, aspect='auto', cmap='gray')\n","    ax[1].set_title('Ground Truth')\n","    ax[2].set_title('Predicción')\n","    ax[2].imshow(red, aspect='auto', cmap = 'gray')\n","    ax[3].imshow(monocroma, aspect='auto', cmap='gray')\n","    ax[3].imshow(etiqueta, cmap = 'Reds', aspect='auto', alpha = 0.4)\n","    ax[3].imshow(red, cmap = 'Blues', aspect='auto', alpha = 0.4)"]},{"cell_type":"markdown","metadata":{"id":"gTfNz5R8dtZC"},"source":["## Leer las imagenes"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4136,"status":"ok","timestamp":1696971902987,"user":{"displayName":"Valeria Rulloni","userId":"07246783771048703942"},"user_tz":180},"id":"ZYxmR4-qyJl9","outputId":"d29d448a-c7bd-43c8-f661-04a67e7667bf"},"outputs":[{"name":"stdout","output_type":"stream","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}],"source":["# Este comando es para leer los archivos directamente desde Drive\n","\n","from google.colab import drive\n","drive.mount('/content/drive')\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Zm2_t56VyL-b"},"outputs":[],"source":["path_train = \"/content/drive/MyDrive/Proyecto_Sadosky/base_final/clean_database/train\"\n","path_test = \"/content/drive/MyDrive/Proyecto_Sadosky/base_final/clean_database/test\"\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"6SEJX4il15py"},"outputs":[],"source":["path_train = \"/content/drive/MyDrive/Sadosky_EcoDoppler/Investigación/Procesamiento/base_final/clean_database/train\"\n","path_test = \"/content/drive/MyDrive/Sadosky_EcoDoppler/Investigación/Procesamiento/base_final/clean_database/test\"\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":18,"status":"ok","timestamp":1696971902989,"user":{"displayName":"Valeria Rulloni","userId":"07246783771048703942"},"user_tz":180},"id":"8PvNnsd0RweL","outputId":"f2989b9f-001f-49c6-9102-0828483be631"},"outputs":[{"name":"stdout","output_type":"stream","text":["Total number of Train images: 493\n","['52.png', '327.png', '334.png', '435.png', '402.png', '78.png', '431.png', '446.png', '221.png', '313.png', '355.png', '37.png', '51.png', '3.png', '194.png', '375.png', '331.png', '211.png', '311.png', '162.png', '275.png', '551.png', '428.png', '349.png', '427.png', '492.png', '63.png', '400.png', '208.png', '181.png', '388.png', '387.png', '235.png', '44.png', '60.png', '92.png', '99.png', '360.png', '470.png', '406.png', '302.png', '437.png', '125.png', '111.png', '246.png', '405.png', '298.png', '184.png', '410.png', '290.png', '13.png', '322.png', '158.png', '479.png', '175.png', '183.png', '214.png', '58.png', '484.png', '367.png', '4.png', '303.png', '373.png', '383.png', '197.png', '103.png', '128.png', '163.png', '276.png', '220.png', '323.png', '29.png', '363.png', '421.png', '397.png', '493.png', '178.png', '200.png', '226.png', '199.png', '54.png', '112.png', '108.png', '372.png', '230.png', '379.png', '46.png', '216.png', '356.png', '384.png', '147.png', '419.png', '261.png', '215.png', '166.png', '209.png', '132.png', '143.png', '105.png', '171.png', '381.png', '222.png', '96.png', '80.png', '254.png', '320.png', '117.png', '219.png', '129.png', '364.png', '361.png', '266.png', '100.png', '495.png', '351.png', '85.png', '48.png', '337.png', '95.png', '352.png', '131.png', '389.png', '140.png', '91.png', '348.png', '251.png', '441.png', '30.png', '33.png', '36.png', '79.png', '236.png', '41.png', '408.png', '154.png', '359.png', '288.png', '232.png', '265.png', '50.png', '182.png', '229.png', '27.png', '461.png', '118.png', '64.png', '38.png', '460.png', '6.png', '316.png', '471.png', '76.png', '274.png', '295.png', '35.png', '81.png', '312.png', '202.png', '205.png', '177.png', '473.png', '350.png', '161.png', '233.png', '324.png', '425.png', '329.png', '190.png', '347.png', '304.png', '256.png', '255.png', '68.png', '462.png', '248.png', '238.png', '422.png', '339.png', '14.png', '74.png', '424.png', '142.png', '434.png', '245.png', '17.png', '550.png', '342.png', '357.png', '241.png', '133.png', '466.png', '191.png', '268.png', '136.png', '377.png', '39.png', '146.png', '385.png', '480.png', '82.png', '45.png', '87.png', '399.png', '106.png', '305.png', '206.png', '443.png', '153.png', '174.png', '61.png', '152.png', '455.png', '330.png', '239.png', '25.png', '336.png', '16.png', '429.png', '1.png', '308.png', '264.png', '440.png', '283.png', '57.png', '257.png', '159.png', '548.png', '546.png', '414.png', '448.png', '42.png', '346.png', '203.png', '43.png', '258.png', '224.png', '395.png', '192.png', '210.png', '465.png', '284.png', '318.png', '18.png', '110.png', '273.png', '278.png', '270.png', '296.png', '286.png', '97.png', '47.png', '391.png', '75.png', '212.png', '86.png', '70.png', '53.png', '404.png', '179.png', '287.png', '486.png', '151.png', '98.png', '293.png', '438.png', '415.png', '23.png', '326.png', '487.png', '104.png', '376.png', '547.png', '164.png', '101.png', '294.png', '394.png', '449.png', '201.png', '188.png', '240.png', '66.png', '417.png', '411.png', '65.png', '483.png', '130.png', '358.png', '253.png', '472.png', '11.png', '67.png', '71.png', '149.png', '365.png', '463.png', '476.png', '56.png', '34.png', '344.png', '281.png', '107.png', '467.png', '353.png', '354.png', '453.png', '451.png', '369.png', '338.png', '444.png', '144.png', '207.png', '40.png', '120.png', '244.png', '482.png', '445.png', '423.png', '94.png', '77.png', '155.png', '291.png', '464.png', '168.png', '475.png', '138.png', '436.png', '317.png', '271.png', '452.png', '488.png', '135.png', '341.png', '454.png', '267.png', '409.png', '307.png', '198.png', '279.png', '366.png', '49.png', '332.png', '160.png', '250.png', '382.png', '137.png', '195.png', '390.png', '549.png', '186.png', '280.png', '121.png', '122.png', '225.png', '249.png', '277.png', '172.png', '340.png', '170.png', '26.png', '319.png', '124.png', '401.png', '102.png', '55.png', '204.png', '412.png', '114.png', '328.png', '223.png', '371.png', '439.png', '314.png', '333.png', '189.png', '432.png', '242.png', '269.png', '31.png', '234.png', '115.png', '19.png', '116.png', '430.png', '262.png', '370.png', '90.png', '156.png', '193.png', '297.png', '227.png', '24.png', '396.png', '481.png', '9.png', '32.png', '392.png', '84.png', '468.png', '180.png', '420.png', '380.png', '139.png', '263.png', '196.png', '217.png', '552.png', '169.png', '126.png', '218.png', '489.png', '10.png', '157.png', '62.png', '123.png', '134.png', '252.png', '457.png', '386.png', '150.png', '418.png', '165.png', '426.png', '8.png', '69.png', '491.png', '185.png', '237.png', '228.png', '325.png', '378.png', '83.png', '148.png', '20.png', '109.png', '456.png', '93.png', '321.png', '398.png', '119.png', '272.png', '496.png', '335.png', '301.png', '416.png', '73.png', '306.png', '7.png', '260.png', '478.png', '113.png', '2.png', '368.png', '469.png', '345.png', '127.png', '343.png', '362.png', '433.png', '292.png', '259.png', '300.png', '285.png', '442.png', '5.png', '450.png', '490.png', '374.png', '310.png', '494.png', '407.png', '403.png', '474.png', '15.png', '145.png', '309.png', '59.png', '393.png', '315.png', '413.png', '28.png', '485.png', '299.png', '447.png', '12.png', '477.png', '88.png', '289.png', '459.png', '72.png', '458.png', '231.png', '89.png', '213.png']\n"]}],"source":["#database_path = os.path.join(path_train, \"clean_png_train\")\n","database_path = path_train\n","\n","files_train = os.listdir(database_path)\n","\n","images_train = [item for item in files_train if 'labeled' not in item]\n","\n","\n","random.shuffle(images_train)\n","\n","print(f'Total number of Train images: {len(images_train)}')\n","print(images_train)\n","\n","\n","train_ids = images_train"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"5JhLP72E-24Q"},"outputs":[],"source":["train_images = []\n","train_masks = []\n","\n","for image_id in train_ids:\n","\n","\n","    image_path = os.path.join(database_path, str(image_id))\n","    train_images.append(image_path)\n","    mask_path = os.path.join(database_path, image_id.replace(\".png\",\"\")) + \"_labeled.png\"\n","    train_masks.append(mask_path)"]},{"cell_type":"markdown","metadata":{"id":"havW4N9dKacO"},"source":["## Cargo las imagenes en memoria"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"6wyOOkSYRx6X"},"outputs":[],"source":["Xtrain = []\n","\n","Ytrain = []\n","\n","\n","for image_id in train_ids:\n","\n","\n","    image_path = os.path.join(database_path, str(image_id))\n","    mask_path = os.path.join(database_path, image_id.replace(\".png\",\"\")) + \"_labeled.png\"\n","    image = cv2.imread(image_path, 0)\n","    mask = cv2.imread(mask_path, 0)\n","    Xtrain.append(image)\n","    Ytrain.append(mask)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"k0K248PBTpjV"},"outputs":[],"source":["# hacemos la aumentacion de datos de train\n","\n","X_train_data_augmentation = DataAugmentation(Xtrain)\n","X_train_data_augmentation.process_images()\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"CBlmuA0sV_VM"},"outputs":[],"source":["Xtrain =  X_train_data_augmentation.output\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":28,"status":"ok","timestamp":1696971918088,"user":{"displayName":"Valeria Rulloni","userId":"07246783771048703942"},"user_tz":180},"id":"ykUpYoGWRzVJ","outputId":"e2e93c8e-5959-4444-adf6-56b20e32c5ec"},"outputs":[{"name":"stdout","output_type":"stream","text":["Xtrain: (7888, 512, 512)\n"]}],"source":["X_train = np.asarray(Xtrain, dtype=np.uint8)\n","print('Xtrain:',X_train.shape)\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"OMxbop-CPRnK"},"outputs":[],"source":["Y_train_data_augmentation = DataAugmentation(Ytrain)\n","Y_train_data_augmentation.process_images()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"AsDIvqhz86Z9"},"outputs":[],"source":["Ytrain = Y_train_data_augmentation.output"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":23,"status":"ok","timestamp":1696971920874,"user":{"displayName":"Valeria Rulloni","userId":"07246783771048703942"},"user_tz":180},"id":"eu9NaRYicm15","outputId":"2e4a067b-34b2-483b-9867-ee969178af98"},"outputs":[{"name":"stdout","output_type":"stream","text":["(512, 512)\n"]}],"source":["print(Y_train_data_augmentation.output[1].shape)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":21,"status":"ok","timestamp":1696971920875,"user":{"displayName":"Valeria Rulloni","userId":"07246783771048703942"},"user_tz":180},"id":"5HgbAFod8uKf","outputId":"13e33bba-2a08-4208-8521-1f9baf777863"},"outputs":[{"name":"stdout","output_type":"stream","text":["Ytrain: (7888, 512, 512)\n"]}],"source":["Y_train = np.asarray(Ytrain, dtype=bool)\n","print('Ytrain:',Y_train.shape)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":16,"status":"ok","timestamp":1696971920875,"user":{"displayName":"Valeria Rulloni","userId":"07246783771048703942"},"user_tz":180},"id":"pP1favTRkEF-","outputId":"ad117020-8786-468c-d712-f6a65f46dec9"},"outputs":[{"data":{"text/plain":["7888"]},"execution_count":19,"metadata":{},"output_type":"execute_result"}],"source":["len(X_train)"]},{"cell_type":"markdown","metadata":{"id":"78KhAvLYd0b4"},"source":["## Metricas para medir el desempeno de la red"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"1N30Q11wZn7Y"},"outputs":[],"source":["import tensorflow.keras.backend as K\n","\n","# intersection over union\n","\n","def jacard_coef(y_true, y_pred):\n","    y_true = tf.cast(y_true, tf.float32)\n","    y_pred = tf.cast(y_pred, tf.float32)\n","\n","    intersection = K.sum(y_true * y_pred)\n","\n","    return (intersection + 1.0) / (K.sum(y_true) + K.sum(y_pred) - intersection + 1.0)\n","\n","def jacard_coef_loss(y_true, y_pred):\n","    return -jacard_coef(y_true, y_pred)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"1EI1oSHQpZuh"},"outputs":[],"source":["def jacard_coef_np(y_true, y_pred):\n","  y_true=y_true.astype('float32')\n","  y_pred=y_pred.astype('float32')\n","  intersection = np.sum(y_true * y_pred)\n","  return (intersection + 1.0) / (np.sum(y_true) + np.sum(y_pred) - intersection + 1.0)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"9OwmYIGUVT6e"},"outputs":[],"source":["def dice_coef_np(y_true, y_pred):\n","  y_true=y_true.astype('float32')\n","  y_pred=y_pred.astype('float32')\n","  intersection = np.sum(y_true * y_pred)\n","  return (2*intersection + 1.0) / (np.sum(y_true) + np.sum(y_pred) + 1.0)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"5kzbNkGddzFn"},"outputs":[],"source":["import tensorflow.keras.backend as K\n","\n","def dice_coefficient(y_true, y_pred, smooth=1):\n","    y_true = tf.cast(y_true, tf.float32)\n","    y_pred = tf.cast(y_pred, tf.float32)\n","\n","    intersection = K.sum(y_true * y_pred)\n","    suma = K.sum(y_true) + K.sum(y_pred)\n","    dice = (2.0 * intersection + smooth) / (suma + smooth)\n","    return dice\n","\n","def dice_coef_loss(y_true, y_pred):\n","    return 1 - dice_coefficient(y_true, y_pred)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"-cx1gyXKuQOi"},"outputs":[],"source":["import tensorflow as tf\n","# este no funciona\n","\n","def dice_loss_modif0(y_true, y_pred, smooth=1e-5):\n","    y_true = tf.cast(y_true, tf.float32)\n","\n","    if sum(y_true) == 0:               #se agrega para controlar los falsos positivos cuando no hay placa en el Ground Truth\n","      # no tengo placa\n","      dice_loss = tf.reduce_sum(y_pred) * smooth #en nuestro caso también puede ser /(512**2)\n","\n","    else:\n","      intersection = tf.reduce_sum(y_true * y_pred)\n","      suma = tf.reduce_sum(y_true) + tf.reduce_sum(y_pred)\n","      dice_score = (2.0 * intersection + smooth) / (suma + smooth)\n","      dice_loss = 1.0 - dice_score\n","\n","    return dice_loss"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"W8IYZgxpvcKJ"},"outputs":[],"source":["import tensorflow as tf\n","# este no funciona bien para smooth=1e-5\n","\n","def dice_loss_modif(y_true, y_pred, smooth=1e-6):\n","    y_true = tf.cast(y_true, tf.float32)\n","    intersection = tf.reduce_sum(y_true * y_pred)\n","    union = tf.reduce_sum(y_true) + tf.reduce_sum(y_pred)\n","    dice_score = (2.0 * intersection + smooth) / (union + smooth)\n","    dice_loss = - dice_score+(tf.reduce_sum(y_pred)*smooth)**2\n","    return dice_loss"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Y5Rpfb8TZm2w"},"outputs":[],"source":["import tensorflow as tf\n","\n","def dice_loss(y_true, y_pred, smooth=1): #smooth=1e-5\n","    y_true = tf.cast(y_true, tf.float32)\n","    intersection = tf.reduce_sum(y_true * y_pred)\n","    suma = tf.reduce_sum(y_true) + tf.reduce_sum(y_pred)\n","    dice_score = (2.0 * intersection + smooth) / (suma + smooth)\n","    dice_loss = 1.0 - dice_score\n","    return dice_loss"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"scjNIn99ErVO"},"outputs":[],"source":["def weighted_binary_crossentropy(y_true, y_pred):\n","\n","    one_weight = 0.89\n","    zero_weight = 0.11\n","    # Original binary crossentropy (see losses.py):\n","    # K.mean(K.binary_crossentropy(y_true, y_pred), axis=-1)\n","\n","    # Calculate the binary crossentropy\n","    y_true = tf.cast(y_true, tf.float32)\n","    b_ce = K.binary_crossentropy(y_true, y_pred)\n","\n","    # Apply the weights\n","    weight_vector = y_true * one_weight + (1. - y_true) * zero_weight\n","    weighted_b_ce = weight_vector * b_ce\n","\n","    # Return the mean error\n","    return K.mean(weighted_b_ce)"]},{"cell_type":"markdown","metadata":{"id":"4wbC2y6bKsTl"},"source":["## Modelo de Red neuronal"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"P1pJCpA8OaK4"},"outputs":[],"source":["from tensorflow.keras.applications.vgg16 import VGG16, preprocess_input\n","from keras.layers import concatenate, Conv2DTranspose, Conv2D, Dropout\n","from keras.layers import Input\n","from keras.models import Model\n","\n","\n","# https://github.com/dorltcheng/Transfer-Learning-U-Net-Deep-Learning-for-Lung-Ultrasound-Segmentation/blob/main/V_Unet/V_Unet_v1_1.ipynb\n","\n","from tensorflow.keras.regularizers import l2\n","\n","def TL_unet_model(input_shape, dropout_rate=0.5, l2_penalty=1e-3):\n","    # input: input_shape (height, width, channels)\n","    # return model\n","\n","    img_input = Input(shape=(input_shape, input_shape, 1))\n","    img_conc = concatenate(([img_input, img_input, img_input]))\n","\n","\n","    base_VGG = VGG16(include_top = False,\n","                   weights = \"imagenet\",\n","                   input_tensor=img_conc)\n","\n","    # freezing all layers in VGG16\n","    for layer in base_VGG.layers:\n","        layer.trainable = False\n","\n","    # the bridge (exclude the last maxpooling layer in VGG16)\n","    # bridge = base_VGG.get_layer(\"block5_conv3\").output\n","\n","    bridge = base_VGG.output\n","\n","    print(bridge.shape)\n","\n","    # Decoder now\n","    up1 = Conv2DTranspose(512, (2, 2), strides=(2, 2), padding='same')(bridge)\n","    print(up1.shape)\n","    concat_1 = concatenate([up1, base_VGG.get_layer(\"block5_conv3\").output], axis=3)\n","    conv6 = Conv2D(512, (3, 3), activation='relu', padding='same')(concat_1)\n","    conv6 = Conv2D(512, (3, 3), activation='relu', padding='same')(conv6)\n","    conv6 = Dropout(dropout_rate)(conv6)\n","\n","    up2 = Conv2DTranspose(256, (2, 2), strides=(2, 2), padding='same')(conv6)\n","    print(up2.shape)\n","    concat_2 = concatenate([up2, base_VGG.get_layer(\"block4_conv3\").output], axis=3)\n","    conv7 = Conv2D(256, (3, 3), activation='relu', padding='same')(concat_2)\n","    conv7 = Conv2D(256, (3, 3), activation='relu', padding='same')(conv7)\n","    conv7 = Dropout(dropout_rate)(conv7)\n","\n","    up3 = Conv2DTranspose(128, (2, 2), strides=(2, 2), padding='same')(conv7)\n","    print(up3.shape)\n","    concat_3 = concatenate([up3, base_VGG.get_layer(\"block3_conv3\").output], axis=3)\n","    conv8 = Conv2D(128, (3, 3), activation='relu', padding='same')(concat_3)\n","    conv8 = Conv2D(128, (3, 3), activation='relu', padding='same')(conv8)\n","    conv8 = Dropout(dropout_rate)(conv8)\n","\n","    up4 = Conv2DTranspose(64, (2, 2), strides=(2, 2), padding='same')(conv8)\n","    print(up4.shape)\n","    concat_4 = concatenate([up4, base_VGG.get_layer(\"block2_conv2\").output], axis=3)\n","    conv9 = Conv2D(64, (3, 3), activation='relu', padding='same')(concat_4)\n","    conv9 = Conv2D(64, (3, 3), activation='relu', padding='same')(conv9)\n","    conv9 = Dropout(dropout_rate)(conv9)\n","\n","    # probando\n","    up5 = Conv2DTranspose(32, (2, 2), strides=(2, 2), padding='same')(conv9)\n","    print(up5.shape)\n","    concat_5 = concatenate([up5, base_VGG.get_layer(\"block1_conv2\").output], axis=3)\n","    conv10 = Conv2D(32, (3, 3), activation='relu', padding='same')(concat_5)\n","    conv10 = Conv2D(32, (3, 3), activation='relu', padding='same')(conv10)\n","    conv10 = Dropout(dropout_rate)(conv10)\n","\n","    conv11 = Conv2D(1, (1, 1), activation='sigmoid')(conv10)\n","    print(conv11.shape)\n","\n","    model = Model(inputs=[base_VGG.input], outputs=[conv11])\n","\n","    return model"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3694,"status":"ok","timestamp":1696971925057,"user":{"displayName":"Valeria Rulloni","userId":"07246783771048703942"},"user_tz":180},"id":"fuClH6_OfkLL","outputId":"71801732-6a01-477f-cdd2-637435eee10f"},"outputs":[{"name":"stdout","output_type":"stream","text":["(None, 16, 16, 512)\n","(None, 32, 32, 512)\n","(None, 64, 64, 256)\n","(None, 128, 128, 128)\n","(None, 256, 256, 64)\n","(None, 512, 512, 32)\n","(None, 512, 512, 1)\n","Model: \"model\"\n","__________________________________________________________________________________________________\n"," Layer (type)                Output Shape                 Param #   Connected to                  \n","==================================================================================================\n"," input_1 (InputLayer)        [(None, 512, 512, 1)]        0         []                            \n","                                                                                                  \n"," concatenate (Concatenate)   (None, 512, 512, 3)          0         ['input_1[0][0]',             \n","                                                                     'input_1[0][0]',             \n","                                                                     'input_1[0][0]']             \n","                                                                                                  \n"," block1_conv1 (Conv2D)       (None, 512, 512, 64)         1792      ['concatenate[0][0]']         \n","                                                                                                  \n"," block1_conv2 (Conv2D)       (None, 512, 512, 64)         36928     ['block1_conv1[0][0]']        \n","                                                                                                  \n"," block1_pool (MaxPooling2D)  (None, 256, 256, 64)         0         ['block1_conv2[0][0]']        \n","                                                                                                  \n"," block2_conv1 (Conv2D)       (None, 256, 256, 128)        73856     ['block1_pool[0][0]']         \n","                                                                                                  \n"," block2_conv2 (Conv2D)       (None, 256, 256, 128)        147584    ['block2_conv1[0][0]']        \n","                                                                                                  \n"," block2_pool (MaxPooling2D)  (None, 128, 128, 128)        0         ['block2_conv2[0][0]']        \n","                                                                                                  \n"," block3_conv1 (Conv2D)       (None, 128, 128, 256)        295168    ['block2_pool[0][0]']         \n","                                                                                                  \n"," block3_conv2 (Conv2D)       (None, 128, 128, 256)        590080    ['block3_conv1[0][0]']        \n","                                                                                                  \n"," block3_conv3 (Conv2D)       (None, 128, 128, 256)        590080    ['block3_conv2[0][0]']        \n","                                                                                                  \n"," block3_pool (MaxPooling2D)  (None, 64, 64, 256)          0         ['block3_conv3[0][0]']        \n","                                                                                                  \n"," block4_conv1 (Conv2D)       (None, 64, 64, 512)          1180160   ['block3_pool[0][0]']         \n","                                                                                                  \n"," block4_conv2 (Conv2D)       (None, 64, 64, 512)          2359808   ['block4_conv1[0][0]']        \n","                                                                                                  \n"," block4_conv3 (Conv2D)       (None, 64, 64, 512)          2359808   ['block4_conv2[0][0]']        \n","                                                                                                  \n"," block4_pool (MaxPooling2D)  (None, 32, 32, 512)          0         ['block4_conv3[0][0]']        \n","                                                                                                  \n"," block5_conv1 (Conv2D)       (None, 32, 32, 512)          2359808   ['block4_pool[0][0]']         \n","                                                                                                  \n"," block5_conv2 (Conv2D)       (None, 32, 32, 512)          2359808   ['block5_conv1[0][0]']        \n","                                                                                                  \n"," block5_conv3 (Conv2D)       (None, 32, 32, 512)          2359808   ['block5_conv2[0][0]']        \n","                                                                                                  \n"," block5_pool (MaxPooling2D)  (None, 16, 16, 512)          0         ['block5_conv3[0][0]']        \n","                                                                                                  \n"," conv2d_transpose (Conv2DTr  (None, 32, 32, 512)          1049088   ['block5_pool[0][0]']         \n"," anspose)                                                                                         \n","                                                                                                  \n"," concatenate_1 (Concatenate  (None, 32, 32, 1024)         0         ['conv2d_transpose[0][0]',    \n"," )                                                                   'block5_conv3[0][0]']        \n","                                                                                                  \n"," conv2d (Conv2D)             (None, 32, 32, 512)          4719104   ['concatenate_1[0][0]']       \n","                                                                                                  \n"," conv2d_1 (Conv2D)           (None, 32, 32, 512)          2359808   ['conv2d[0][0]']              \n","                                                                                                  \n"," dropout (Dropout)           (None, 32, 32, 512)          0         ['conv2d_1[0][0]']            \n","                                                                                                  \n"," conv2d_transpose_1 (Conv2D  (None, 64, 64, 256)          524544    ['dropout[0][0]']             \n"," Transpose)                                                                                       \n","                                                                                                  \n"," concatenate_2 (Concatenate  (None, 64, 64, 768)          0         ['conv2d_transpose_1[0][0]',  \n"," )                                                                   'block4_conv3[0][0]']        \n","                                                                                                  \n"," conv2d_2 (Conv2D)           (None, 64, 64, 256)          1769728   ['concatenate_2[0][0]']       \n","                                                                                                  \n"," conv2d_3 (Conv2D)           (None, 64, 64, 256)          590080    ['conv2d_2[0][0]']            \n","                                                                                                  \n"," dropout_1 (Dropout)         (None, 64, 64, 256)          0         ['conv2d_3[0][0]']            \n","                                                                                                  \n"," conv2d_transpose_2 (Conv2D  (None, 128, 128, 128)        131200    ['dropout_1[0][0]']           \n"," Transpose)                                                                                       \n","                                                                                                  \n"," concatenate_3 (Concatenate  (None, 128, 128, 384)        0         ['conv2d_transpose_2[0][0]',  \n"," )                                                                   'block3_conv3[0][0]']        \n","                                                                                                  \n"," conv2d_4 (Conv2D)           (None, 128, 128, 128)        442496    ['concatenate_3[0][0]']       \n","                                                                                                  \n"," conv2d_5 (Conv2D)           (None, 128, 128, 128)        147584    ['conv2d_4[0][0]']            \n","                                                                                                  \n"," dropout_2 (Dropout)         (None, 128, 128, 128)        0         ['conv2d_5[0][0]']            \n","                                                                                                  \n"," conv2d_transpose_3 (Conv2D  (None, 256, 256, 64)         32832     ['dropout_2[0][0]']           \n"," Transpose)                                                                                       \n","                                                                                                  \n"," concatenate_4 (Concatenate  (None, 256, 256, 192)        0         ['conv2d_transpose_3[0][0]',  \n"," )                                                                   'block2_conv2[0][0]']        \n","                                                                                                  \n"," conv2d_6 (Conv2D)           (None, 256, 256, 64)         110656    ['concatenate_4[0][0]']       \n","                                                                                                  \n"," conv2d_7 (Conv2D)           (None, 256, 256, 64)         36928     ['conv2d_6[0][0]']            \n","                                                                                                  \n"," dropout_3 (Dropout)         (None, 256, 256, 64)         0         ['conv2d_7[0][0]']            \n","                                                                                                  \n"," conv2d_transpose_4 (Conv2D  (None, 512, 512, 32)         8224      ['dropout_3[0][0]']           \n"," Transpose)                                                                                       \n","                                                                                                  \n"," concatenate_5 (Concatenate  (None, 512, 512, 96)         0         ['conv2d_transpose_4[0][0]',  \n"," )                                                                   'block1_conv2[0][0]']        \n","                                                                                                  \n"," conv2d_8 (Conv2D)           (None, 512, 512, 32)         27680     ['concatenate_5[0][0]']       \n","                                                                                                  \n"," conv2d_9 (Conv2D)           (None, 512, 512, 32)         9248      ['conv2d_8[0][0]']            \n","                                                                                                  \n"," dropout_4 (Dropout)         (None, 512, 512, 32)         0         ['conv2d_9[0][0]']            \n","                                                                                                  \n"," conv2d_10 (Conv2D)          (None, 512, 512, 1)          33        ['dropout_4[0][0]']           \n","                                                                                                  \n","==================================================================================================\n","Total params: 26673921 (101.75 MB)\n","Trainable params: 11959233 (45.62 MB)\n","Non-trainable params: 14714688 (56.13 MB)\n","__________________________________________________________________________________________________\n"]}],"source":["from tensorflow.keras.optimizers import Adam\n","\n","# NOTA: cuando uso \"adam\", sin especificar el Learning rate, el algoritmo no converge y hace todo mal\n","\n","# model = model_build_func((512, 512, 1),1,True)\n","model = TL_unet_model(512)\n","model.compile(optimizer=Adam(learning_rate=1e-4), loss=[dice_loss], metrics=[jacard_coef])\n","# model.compile(optimizer=\"sgd\", loss=[dice_loss], metrics=[jacard_coef])\n","model.summary()"]},{"cell_type":"markdown","metadata":{"id":"-FC51GBId9bl"},"source":["## Entrenamiento"]},{"cell_type":"markdown","metadata":{"id":"74g26YQXUWv_"},"source":["## path resultados del modelo"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"hmSAzNb5dY_0"},"outputs":[],"source":["path='/content/drive/MyDrive/Proyecto_Sadosky/modelo_final/resultados/VGG16/'\n","path =\"/content/drive/MyDrive/Sadosky_EcoDoppler/Investigación/Procesamiento/modelo_final/resultados/VGG16/\""]},{"cell_type":"code","execution_count":null,"metadata":{"id":"YmWovB8EdR-x"},"outputs":[],"source":["from tensorflow.keras.callbacks import ModelCheckpoint"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/"},"id":"52jCLuVYbr6K","outputId":"1bf871a5-3a4f-4862-8359-fee5c05999c8"},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch 1/100\n","395/395 [==============================] - ETA: 0s - loss: 0.5883 - jacard_coef: 0.2696\n","Epoch 1: val_loss improved from inf to 0.59286, saving model to /content/drive/MyDrive/Sadosky_EcoDoppler/Investigación/Procesamiento/modelo_final/resultados/VGG16/unet_plaque_segmentation.hdf5\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]},{"name":"stdout","output_type":"stream","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r395/395 [==============================] - 710s 2s/step - loss: 0.5883 - jacard_coef: 0.2696 - val_loss: 0.5929 - val_jacard_coef: 0.2767\n","Epoch 2/100\n"]},{"ename":"ResourceExhaustedError","evalue":"ignored","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)","\u001b[0;32m<ipython-input-32-0adec4b420da>\u001b[0m in \u001b[0;36m<cell line: 15>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0mcallbacks_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mmodel_checkpoint\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_split\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallbacks_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     68\u001b[0m             \u001b[0;31m# To get the full stack trace, call:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m             \u001b[0;31m# `tf.debugging.disable_traceback_filtering()`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     54\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     55\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mResourceExhaustedError\u001b[0m: Graph execution error:\n\nDetected at node 'gradient_tape/model/conv2d_8/Conv2D/Conv2DBackpropInput' defined at (most recent call last):\n    File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n      return _run_code(code, main_globals, None,\n    File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n      exec(code, run_globals)\n    File \"/usr/local/lib/python3.10/dist-packages/colab_kernel_launcher.py\", line 37, in <module>\n      ColabKernelApp.launch_instance()\n    File \"/usr/local/lib/python3.10/dist-packages/traitlets/config/application.py\", line 992, in launch_instance\n      app.start()\n    File \"/usr/local/lib/python3.10/dist-packages/ipykernel/kernelapp.py\", line 619, in start\n      self.io_loop.start()\n    File \"/usr/local/lib/python3.10/dist-packages/tornado/platform/asyncio.py\", line 195, in start\n      self.asyncio_loop.run_forever()\n    File \"/usr/lib/python3.10/asyncio/base_events.py\", line 603, in run_forever\n      self._run_once()\n    File \"/usr/lib/python3.10/asyncio/base_events.py\", line 1909, in _run_once\n      handle._run()\n    File \"/usr/lib/python3.10/asyncio/events.py\", line 80, in _run\n      self._context.run(self._callback, *self._args)\n    File \"/usr/local/lib/python3.10/dist-packages/tornado/ioloop.py\", line 685, in <lambda>\n      lambda f: self._run_callback(functools.partial(callback, future))\n    File \"/usr/local/lib/python3.10/dist-packages/tornado/ioloop.py\", line 738, in _run_callback\n      ret = callback()\n    File \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 825, in inner\n      self.ctx_run(self.run)\n    File \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 786, in run\n      yielded = self.gen.send(value)\n    File \"/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py\", line 377, in dispatch_queue\n      yield self.process_one()\n    File \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 250, in wrapper\n      runner = Runner(ctx_run, result, future, yielded)\n    File \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 748, in __init__\n      self.ctx_run(self.run)\n    File \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 786, in run\n      yielded = self.gen.send(value)\n    File \"/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py\", line 361, in process_one\n      yield gen.maybe_future(dispatch(*args))\n    File \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 234, in wrapper\n      yielded = ctx_run(next, result)\n    File \"/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py\", line 261, in dispatch_shell\n      yield gen.maybe_future(handler(stream, idents, msg))\n    File \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 234, in wrapper\n      yielded = ctx_run(next, result)\n    File \"/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py\", line 539, in execute_request\n      self.do_execute(\n    File \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 234, in wrapper\n      yielded = ctx_run(next, result)\n    File \"/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py\", line 302, in do_execute\n      res = shell.run_cell(code, store_history=store_history, silent=silent)\n    File \"/usr/local/lib/python3.10/dist-packages/ipykernel/zmqshell.py\", line 539, in run_cell\n      return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n    File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 2975, in run_cell\n      result = self._run_cell(\n    File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3030, in _run_cell\n      return runner(coro)\n    File \"/usr/local/lib/python3.10/dist-packages/IPython/core/async_helpers.py\", line 78, in _pseudo_sync_runner\n      coro.send(None)\n    File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3257, in run_cell_async\n      has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n    File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3473, in run_ast_nodes\n      if (await self.run_code(code, result,  async_=asy)):\n    File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3553, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"<ipython-input-32-0adec4b420da>\", line 15, in <cell line: 15>\n      results = model.fit(X_train, Y_train, validation_split=0.2, batch_size=batch_size, epochs=epochs, callbacks=callbacks_list)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 1742, in fit\n      tmp_logs = self.train_function(iterator)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 1338, in train_function\n      return step_function(self, iterator)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 1322, in step_function\n      outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 1303, in run_step\n      outputs = model.train_step(data)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 1084, in train_step\n      self.optimizer.minimize(loss, self.trainable_variables, tape=tape)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/optimizers/optimizer.py\", line 543, in minimize\n      grads_and_vars = self.compute_gradients(loss, var_list, tape)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/optimizers/optimizer.py\", line 276, in compute_gradients\n      grads = tape.gradient(loss, var_list)\nNode: 'gradient_tape/model/conv2d_8/Conv2D/Conv2DBackpropInput'\nOOM when allocating tensor with shape[16,96,512,512] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[{{node gradient_tape/model/conv2d_8/Conv2D/Conv2DBackpropInput}}]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info. This isn't available when running in Eager mode.\n [Op:__inference_train_function_4839]"]}],"source":["## Validation Data Size  80:20\n","\n","epochs = 10\n","batch_size = 16 # con 32 me da error\n","\n","checkpoint_path = path+'unet_plaque_segmentation.hdf5'\n","\n","model_checkpoint = ModelCheckpoint(checkpoint_path,\n","                                    verbose=1,\n","                                    monitor='val_loss',\n","                                    save_best_only=True)\n","\n","callbacks_list = [model_checkpoint]\n","\n","results = model.fit(X_train, Y_train, validation_split=0.2, batch_size=batch_size, epochs=epochs, callbacks=callbacks_list)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"Xj6y4W-QfJxo"},"outputs":[],"source":["\n","#from tensorflow.keras.models import load_model\n","#checkpoint_path = path+'unet_plaque_segmentation.hdf5'\n","\n","#model = load_model(checkpoint_path,\n","#                     custom_objects={'dice_loss': dice_loss, 'jacard_coef': jacard_coef})"]},{"cell_type":"markdown","metadata":{"id":"E7fSajrlK4PH"},"source":["## Ver desempeno de la red"]},{"cell_type":"markdown","metadata":{"id":"-M9we__BgtEP"},"source":["## visualizamos curvas de entrenamiento"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"3wARNkR-iN_X"},"outputs":[],"source":["## visualizamos curvas de entrenamiento\n","\n","plt.figure()\n","plt.title(\"Jaccard vs epochs\")\n","plt.plot( results.history['jacard_coef'] )\n","plt.plot( results.history['val_jacard_coef'] )\n","plt.legend(['Training Jaccard', 'Validation Jaccard'])\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"BZt7DxWEiN_Y"},"outputs":[],"source":["plt.figure()\n","plt.title(\"Loss vs epochs\")\n","plt.plot( results.history['loss'] )\n","plt.plot( results.history['val_loss'] )\n","plt.legend(['Training Loss', 'Validation Loss'])\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"ICgekI1nscz4"},"outputs":[],"source":["l=results.history['loss']\n","path_loss=path+'history_loss.txt'\n","np.savetxt(path_loss, l)\n","\n","vl=results.history['val_loss']\n","path_v_loss=path+'history_val_loss.txt'\n","np.savetxt(path_v_loss, vl)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"kaCFV9JltJGU"},"outputs":[],"source":["l=results.history['jacard_coef']\n","path_J=path+'history_Jaccard.txt'\n","np.savetxt(path_J, l)\n","\n","vl=results.history['val_jacard_coef']\n","path_v_J=path+'history_val_Jaccard.txt'\n","np.savetxt(path_v_J, vl)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"8Fc2sacbcyZ1"},"outputs":[],"source":["## visualizamos curvas de entrenamiento\n","\n","plt.figure()\n","plt.title(\"Jaccard vs epochs\")\n","plt.plot( results.history['jacard_coef'] )\n","plt.plot( results.history['val_jacard_coef'] )\n","plt.legend(['Training Jaccard', 'Validation Jaccard'])\n","plt.show()\n","path1=path+\"Jaccard_vs_epochs.png\"\n","plt.savefig(path1)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"328pmIvwIgu4"},"outputs":[],"source":["plt.figure()\n","plt.title(\"Loss vs epochs\")\n","plt.plot( results.history['loss'] )\n","plt.plot( results.history['val_loss'] )\n","plt.legend(['Training Loss', 'Validation Loss'])\n","plt.show()\n","path2=path+\"DICE_Loss_vs_epochs.png\"\n","plt.savefig(path2)"]},{"cell_type":"markdown","metadata":{"id":"98P_BL4ORr9X"},"source":["# Test"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"zm4lHev9Qgr2"},"outputs":[],"source":["#database_path_test = os.path.join(path_test, \"clean_png_test\")\n","database_path_test = path_test\n","\n","files_test = os.listdir(database_path_test)\n","\n","images_test = [item for item in files_test if 'labeled' not in item]\n","\n","print(f'Total number of Test images: {len(images_test)}')\n","print(images_test)\n","\n","test_ids = images_test"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"rK_04buXQz8c"},"outputs":[],"source":["Xtest = []\n","Ytest = []\n","\n","for image_id in test_ids:\n","\n","    image_path = os.path.join(database_path_test, str(image_id))\n","    mask_path = os.path.join(database_path_test, image_id.replace(\".png\",\"\")) + \"_labeled.png\"\n","    image = cv2.imread(image_path, 0)\n","    mask = cv2.imread(mask_path, 0)\n","    print(image.shape)\n","    print(mask.shape)\n","    Xtest.append(image[144:656, 144:656]) #eligimos el centro de tam 512x512\n","    Ytest.append(mask[144:656, 144:656]) #eligimos el centro de tam 512x512"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"uKASUhfrhOmD"},"outputs":[],"source":["#armar nueva lista\n","centro_x= 400\n","centro_y=400\n","\n","for r in range(len(test_ids)):\n","  h,w=Xtest[r].shape\n","  imagenvieja=Xtest[r]\n","\n","  if h<800 or w<800:\n","    imagen_auxiliar=np.zeros((800,800),dtype='uint8')\n","    top_y=(800-h)//2\n","    left_x=(800-w)//2\n","    bottom_y = top_y + h\n","    right_x = left_x+w\n","    imagen_auxiliar[top_y:bottom_y, left_x:right_x] = imagenvieja\n","    imagenvieja=imagen_auxiliar\n","\n","\n","  Xtest[r]= imagenvieja[144:656, 144:656]# 512x512 centrado\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"hu9P7u-4nw1N"},"outputs":[],"source":["#armar nueva lista\n","centro_x= 400\n","centro_y=400\n","\n","for r in range(len(test_ids)):\n","  h,w=Ytest[r].shape\n","  imagenvieja=Ytest[r]\n","\n","  if h<800 or w<800:\n","    imagen_auxiliar=np.zeros((800,800),dtype='uint8')\n","    top_y=(800-h)//2\n","    left_x=(800-w)//2\n","    bottom_y = top_y + h\n","    right_x = left_x+w\n","    imagen_auxiliar[top_y:bottom_y, left_x:right_x] = imagenvieja\n","    imagenvieja=imagen_auxiliar\n","\n","\n","  Ytest[r]= imagenvieja[144:656, 144:656]# 512x512 centrado"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"OX1-B180iYay"},"outputs":[],"source":["Y_test = np.asarray(Ytest, dtype=bool)\n","print('Ytrain:',Y_test.shape)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"LhY6N5BtfREW"},"outputs":[],"source":["len(Xtest)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"QwnQRMxcQFlD"},"outputs":[],"source":["X_test = np.asarray(Xtest, dtype=np.uint8)\n","print('Xtest:',X_test.shape)\n","\n","Y_test = np.asarray(Ytest, dtype=bool)\n","print('Ytest:',Y_test.shape)\n","\n","r = random.randint(0, len(X_test)-1)\n","\n","print(X_test[r].shape)\n","print(Y_test[r].shape)"]},{"cell_type":"markdown","metadata":{"id":"TQMVa_R3Rzul"},"source":["## Predichos para test"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"vTA6dJwU2_Qz"},"outputs":[],"source":["preds = model.predict(X_test[0:270])"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"NIocaCM5-2Lw"},"outputs":[],"source":["print(preds.shape)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"i4ZeBp0Kb1qe"},"outputs":[],"source":["## Save the Weights\n","#model.save_weights(\"UNetW.h5\")\n","\n","result = preds\n","\n","# aca tenemos que binarizar la prediccion del modelo\n","result = result > 0.5"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"4BSpNPte_BHV"},"outputs":[],"source":["print(result.shape)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"1StH_fyH_j1H"},"outputs":[],"source":["item = random.randint(0, len(images_test)-1)\n","item = 16\n","monocroma=X_test[item]\n","etiqueta=Y_test[item]\n","red=preds[item]\n","print('imagen'+test_ids[item])\n","image_comparac(monocroma, etiqueta, red)\n","print('Jaccard:', jacard_coef_np(Y_test[item], preds[item][:,:,0]))\n","print('DICE:',dice_coef_np(Y_test[item], preds[item][:,:,0]))\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"5uaRpgoe2td5"},"outputs":[],"source":["item = random.randint(0, len(images_test)-1)\n","item = 16\n","monocroma=X_test[item]\n","etiqueta=Y_test[item]\n","red=preds[item]\n","print('imagen'+test_ids[item])\n","image_comparac(monocroma, etiqueta, red)\n","print('Jaccard:', jacard_coef_np(Y_test[item], preds[item][:,:,0]))\n","print('DICE:',dice_coef_np(Y_test[item], preds[item][:,:,0]))\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"mfADc2TmqLBp"},"outputs":[],"source":["n=len(images_test)\n","for item in range(n):\n","  monocroma=X_test[item]\n","  etiqueta=Y_test[item]\n","  red=preds[item]\n","  print('imagen'+test_ids[item])\n","  image_comparac(monocroma, etiqueta, red)\n","  fname=path+'resultado_imagen_Test_'+test_ids[item]\n","  plt.savefig(fname)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"5IjY19nV_rJj"},"outputs":[],"source":["n=len(images_test)\n","for item in range(n):\n","  monocroma=X_test[item]\n","  etiqueta=Y_test[item]\n","  red=preds[item]\n","  print('imagen'+test_ids[item])\n","  image_comparac(monocroma, etiqueta, red)\n","  fname=path+'resultado_imagen_Test_'+test_ids[item]\n","  plt.savefig(fname)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"w4fzdKYSNjoj"},"outputs":[],"source":["print('Jaccard:',jacard_coef_np(Y_test, preds[:,:,0]))\n","print('DICE:',dice_coef_np(Y_test, preds[:,:,0]))\n","print('Global')\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"L7kG3ZRXNjoz"},"outputs":[],"source":["D=0.0\n","J=0.0\n","for item in range(n):\n","  J=J+jacard_coef_np(Y_test[item], preds[item][:,:,0])\n","  D=D+dice_coef_np(Y_test[item], preds[item][:,:,0])\n","\n","J=J/20\n","D=D/20\n","\n","print('Promedio en Test')\n","print('Jaccard:',J)\n","print('DICE:',D)\n"]},{"cell_type":"markdown","metadata":{"id":"wgYekjMSD89p"},"source":["## Predichos para train"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"jNKGFSwEB3px"},"outputs":[],"source":["pred_train = model.predict(X_train[0:m])"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"wgOWd7s6uIuw"},"outputs":[],"source":["resul_train=pred_train >0.5"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"gJViEhbpS2OP"},"outputs":[],"source":["m=len(images_train)\n","D=0.0\n","J=0.0\n","for item in range(m):\n","  J=J+jacard_coef_np(Y_train[item], pred_train[item][:,:,0])\n","  D=D+dice_coef_np(Y_train[item], pred_train[item][:,:,0])\n","\n","J=J/m\n","D=D/m\n","\n","print('Promedio en Train')\n","print('Jaccard:',J)\n","print('DICE:',D)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"7OWDkLhiBUVZ"},"outputs":[],"source":["item = random.randint(0, n-1)\n","#item = 16\n","monocroma=X_train[item]\n","etiqueta=Y_train[item]\n","red=pred_train[item]\n","print('imagen'+str(item))\n","image_comparac(monocroma, etiqueta, red)\n","print('Jaccard:',jacard_coef_np(Y_train[item], pred_train[item][:,:,0]))\n","print('DICE:',dice_coef_np(Y_train[item], pred_train[item][:,:,0]))"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"5TjZl6Zap0y5"},"outputs":[],"source":["item = random.randint(0, n-1)\n","#item = 16\n","monocroma=X_train[item]\n","etiqueta=Y_train[item]\n","red=pred_train[item]\n","print('imagen'+str(item))\n","image_comparac(monocroma, etiqueta, red)\n","print('Jaccard:',jacard_coef_np(Y_train[item], pred_train[item][:,:,0]))\n","print('DICE:',dice_coef_np(Y_train[item], pred_train[item][:,:,0]))"]}],"metadata":{"accelerator":"GPU","colab":{"machine_shape":"hm","toc_visible":true,"provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}